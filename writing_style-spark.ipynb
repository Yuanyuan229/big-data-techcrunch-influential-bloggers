{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"writing_style-spark.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"F0rxUz4AfHDl","scrolled":true,"outputId":"83ea5b31-7faa-4f95-92d9-ad5823b27fa0","colab":{}},"source":["import pandas as pd\n","\n","import collections as coll\n","import math\n","import pickle\n","import string\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from matplotlib import style\n","from nltk.corpus import cmudict\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","\n","import nltk\n","\n","nltk.download('cmudict')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import col, udf\n","import scipy as sc"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package cmudict to\n","[nltk_data]     /Users/geyuanyuan1/nltk_data...\n","[nltk_data]   Package cmudict is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/geyuanyuan1/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/geyuanyuan1/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JeefgBzORM_K","colab_type":"code","colab":{}},"source":["from pyspark import SparkContext\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAHbHLsIRM_M","colab_type":"code","colab":{}},"source":["spark = SparkSession.builder.appName(\"Blogger_writing_style\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ChQK0_8ubRiW"},"source":["**Import files** "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1mKxleHrBtkT","colab":{}},"source":["posts = spark\\\n","        .read\\\n","        .option('header','false')\\\n","        .option('inferSchema','true')\\\n","        .csv(r'posts.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"glZSN7LefgMS","colab":{}},"source":["colnames=['Post_ID','Title','Blogger_Name','Blogger_ID','Number of comments','Content','URL','Date',\n","          'Number of retrieved inlinks','Number of retrieved comments','Post Length words',\n","          'Post Length words no stopwords','Average word length characters',\n","          'Average word length characters no stopwords','MEIBI score','MEIBIX score']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WQL3Wey-fgK1","colab":{}},"source":["i=0\n","for colname in colnames:\n","    to_replace_str = '_c'+str(i)\n","    posts = posts.withColumnRenamed(to_replace_str, colname)\n","    i += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yfAEvvkRM_a","colab_type":"code","outputId":"30319b84-1710-4c43-9c63-39a6af7bf735","colab":{}},"source":["posts.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+-------+--------------------+-----------------+----------+------------------+--------------------+--------------------+----------+---------------------------+----------------------------+-----------------+------------------------------+------------------------------+-------------------------------------------+-----------+------------+\n","|Post_ID|               Title|     Blogger_Name|Blogger_ID|Number of comments|             Content|                 URL|      Date|Number of retrieved inlinks|Number of retrieved comments|Post Length words|Post Length words no stopwords|Average word length characters|Average word length characters no stopwords|MEIBI score|MEIBIX score|\n","+-------+--------------------+-----------------+----------+------------------+--------------------+--------------------+----------+---------------------------+----------------------------+-----------------+------------------------------+------------------------------+-------------------------------------------+-----------+------------+\n","|      1|We Just Tested Tw...|    Jason Kincaid|         1|                14|During his keynot...|http://techcrunch...|2010-04-01|                          0|                          14|              314|                           223|                      4.130293|                                   5.686099|    0.00000|     0.00000|\n","|      2|Facebook To Launc...|    Jason Kincaid|         1|                30|Later this month ...|http://techcrunch...|2010-04-01|                          0|                          30|              717|                           488|                      4.138177|                                   5.952869|    0.00000|     0.00000|\n","|      3|NYTimes Request C...|Michael Arrington|         2|                38|A NYTimes communi...|http://techcrunch...|2010-04-01|                          4|                          38|              249|                           168|                      3.572614|                                   5.125000|  624.00000|     0.00000|\n","|      4|Google Shows How ...|  Erick Schonfeld|         3|                26|A lot of attentio...|http://techcrunch...|2010-04-01|                         10|                          26|              256|                           172|                      3.628571|                                   5.168605| 1080.00000|     0.00000|\n","|      5|The iPad: Apple&#...|       John Biggs|         4|                49|Something struck ...|http://www.crunch...|2010-04-01|                          1|                          49|              503|                           348|                      3.773279|                                   5.356322|  200.00000|     0.00000|\n","|      6|Blippy Does An En...|    Jason Kincaid|         1|                13|Early this year, ...|http://techcrunch...|2010-04-01|                          1|                          13|              299|                           221|                      4.393728|                                   5.705882|   56.00000|     0.00000|\n","|      7|FreshPlanet Debut...|  Erick Schonfeld|         3|                 5|If you are going ...|http://techcrunch...|2010-04-01|                          1|                           5|              306|                           220|                      4.232877|                                   5.618182|   24.00000|     0.00000|\n","|      8|Twitter Tweaks Se...|       MG Siegler|         5|                 3|As you may have n...|http://techcrunch...|2010-04-01|                          0|                           3|              446|                           300|                      4.004673|                                   5.713333|    0.00000|     0.00000|\n","|      9|Behind The Scenes...|    Jason Kincaid|         1|                 8|Today, millions o...|http://techcrunch...|2010-04-01|                          2|                           8|              419|                           303|                      4.077670|                                   5.544554|   72.00000|     0.00000|\n","|     10|The App Store Is ...|       MG Siegler|         5|                36|Have you been doi...|http://techcrunch...|2010-04-01|                          0|                          35|              304|                           216|                      3.955017|                                   5.291667|    0.00000|     0.00000|\n","|     11|And now we wait f...|   Devin Coldewey|         6|                26|Whether you&#8217...|http://www.crunch...|2010-04-01|                          0|                          22|              482|                           325|                      3.811563|                                   5.476923|    0.00000|     0.00000|\n","|     12|Netflix For The i...|       MG Siegler|         5|                53|Seeing as today i...|http://techcrunch...|2010-04-01|                          3|                          49|              235|                           155|                      3.607306|                                   5.096774|  600.00000|     0.00000|\n","|     13|Conde Nast Cooks ...|        Leena Rao|         7|                 6|We&#8217;ve heard...|http://techcrunch...|2010-04-01|                          1|                           6|              474|                           334|                      4.023861|                                   5.553892|   28.00000|     0.00000|\n","|     14|RethinkDB Raises ...|    Jason Kincaid|         1|                 3|RethinkDB, the st...|http://techcrunch...|2010-04-01|                          0|                           3|              293|                           210|                      4.650177|                                   6.266667|    0.00000|     0.00000|\n","|     15|With 50 Million U...|       MG Siegler|         5|                17|The iPad isn&#821...|http://techcrunch...|2010-04-01|                          1|                          15|              321|                           219|                      3.892857|                                   5.474886|   64.00000|     0.00000|\n","|     16|Omniture And Othe...|  Erick Schonfeld|         3|                 0|Facebook is rampi...|http://techcrunch...|2010-04-01|                          0|                           0|              206|                           153|                      4.292929|                                   5.555556|    0.00000|     0.00000|\n","|     17|Boom! Apple Break...|       MG Siegler|         5|                10|Maybe you&#8217;v...|http://techcrunch...|2010-04-01|                          1|                           9|              239|                           181|                      4.207048|                                   5.276243|   40.00000|     0.00000|\n","|     18|The New York Time...|       Andy Brett|         8|                28|The New York Time...|http://techcrunch...|2010-04-01|                          4|                          27|              651|                           449|                      4.323988|                                   6.182628|  448.00000|     0.00000|\n","|     19|iPad Apps Are Liv...|       MG Siegler|         5|                14|It appears that A...|http://techcrunch...|2010-04-01|                          1|                          13|              124|                            83|                      3.675926|                                   4.783133|   56.00000|     0.00000|\n","|     20|Pixels And Salsa:...|       MG Siegler|         5|                12|As location conti...|http://techcrunch...|2010-04-01|                          2|                          12|              308|                           203|                      3.719064|                                   5.477833|  104.00000|     0.00000|\n","+-------+--------------------+-----------------+----------+------------------+--------------------+--------------------+----------+---------------------------+----------------------------+-----------------+------------------------------+------------------------------+-------------------------------------------+-----------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aREiv0NfG7xA","colab":{}},"source":["#### functions to clean contents"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gWKFcVN0CnqT","colab":{}},"source":["def RemoveSpecialCHs(text):\n","    text = word_tokenize(text)\n","    st = [\",\", \".\", \"'\", \"!\", '\"', \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", '>', \"?\",\n","          \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", '`', \"{\", \"|\", \"}\", '~', '\\t', '\\n']\n","\n","    words = [word for word in text if word not in st]\n","    return words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wLpP6RPtCniG","colab":{}},"source":["def syllable_count_Manual(word):\n","    word = word.lower()\n","    count = 0\n","    vowels = \"aeiouy\"\n","    if word[0] in vowels:\n","        count += 1\n","    for index in range(1, len(word)):\n","        if word[index] in vowels and word[index - 1] not in vowels:\n","            count += 1\n","            if word.endswith(\"e\"):\n","                count -= 1\n","    if count == 0:\n","        count += 1\n","    return count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7iPmbyLuCnkk","colab":{}},"source":["# COUNTS NUMBER OF SYLLABLES\n","\n","def syllable_count(word):\n","    global cmuDictionary\n","    d = cmuDictionary\n","    try:\n","        syl = [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n","    except:\n","        syl = syllable_count_Manual(word)\n","    return syl"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_jUM3dR-F27v"},"source":["#### functions to find  **Lexical Features:**\n","* Average Word Length\n","* Average Sentence Length By Word\n","* Average Sentence Length By Character\n","* Special Character Count\n","* Average Syllable per Word\n","* Functional Words Count\n","* Punctuation Count\n","\n","\n","These are the most basic features one can extract from the text. These features tell us about the structure of the text. For example averages of different counts like word lengths, special characters, punctuations and functional words etc. Functional words are used to express grammatical relationships among other words within a sentence. Secondly, if a word has more syllables then it is most likely to be a difficult word (although not necessary). Avg Syllable per word being the measure of complexity, is used in calculations of many other features related to readability scores described in the sections ahead. Punctuation Countand Special Character Count are straight forward ways to differentiate different genres. For example narrative story and research paper."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3dlJHQMXUaio","colab":{}},"source":["# removing stop words plus punctuation.\n","def Avg_wordLength(text):\n","    try:\n","        text.translate(string.punctuation)\n","        tokens = word_tokenize(text, language='english')\n","        st = [\",\", \".\", \"'\", \"!\", '\"', \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", '>', \"?\",\n","              \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", '`', \"{\", \"|\", \"}\", '~', '\\t', '\\n']\n","        stop = stopwords.words('english') + st\n","        words = [word for word in tokens if word not in stop]\n","        return float(np.average([len(word) for word in words]))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzUtjsgpRM_o","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: Avg_wordLength(text))\n","posts = posts.withColumn('meanwl', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0gYlrf41UiFC","colab":{}},"source":["# returns avg number of words in a sentence\n","def Avg_SentLenghtByWord(text):\n","    try:\n","        tokens = sent_tokenize(text)\n","        return float(np.average([len(token.split()) for token in tokens]))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7J2fglWwRM_r","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: Avg_SentLenghtByWord(text))\n","posts = posts.withColumn('mean', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qpx_5DmZUauY","colab":{}},"source":["# returns avg number of characters in a sentence\n","def Avg_SentLenghtByCh(text):\n","    try:\n","        tokens = sent_tokenize(text)\n","        return float(np.average([len(token) for token in tokens]))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsauBMvGRM_v","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: Avg_SentLenghtByCh(text))\n","posts = posts.withColumn('meansl', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kKJlBuWAUa3D","colab":{}},"source":["# COUNTS SPECIAL CHARACTERS NORMALIZED OVER LENGTH OF CHUNK\n","def CountSpecialCharacter(text):\n","    try:\n","        st = [\"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \"-\", \"/\", \"<\", \"=\", '>',\n","          \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", '`', \"{\", \"|\", \"}\", '~', '\\t', '\\n']\n","        count = 0\n","        for i in text:\n","            if (i in st):\n","                count = count + 1\n","        return float(count / len(text))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSzbTLGURM_0","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: CountSpecialCharacter(text))\n","posts = posts.withColumn('means', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a1f4a3NpUa_2","colab":{}},"source":["# GIVES NUMBER OF SYLLABLES PER WORD\n","def Avg_Syllable_per_Word(text):\n","    try:\n","        tokens = word_tokenize(text, language='english')\n","        st = [\",\", \".\", \"'\", \"!\", '\"', \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", '>', \"?\",\n","              \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", '`', \"{\", \"|\", \"}\", '~', '\\t', '\\n']\n","        stop = stopwords.words('english') + st\n","        words = [word for word in tokens if word not in stop]\n","        syllabls = [syllable_count(word) for word in words]\n","        p = (\" \".join(words))\n","        return float(sum(syllabls) / max(1, len(words)))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyYFQJPkRM_4","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: Avg_Syllable_per_Word(text))\n","posts = posts.withColumn('meanSyllable', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZeLaDPfqUbI-","colab":{}},"source":["# RETURNS NORMALIZED COUNT OF FUNCTIONAL WORDS FROM A Framework for\n","# Authorship Identification of Online Messages: Writing-Style Features and Classification Techniques\n","\n","def CountFunctionalWords(text):\n","    try:\n","        functional_words = \"\"\"a between in nor some upon\n","        about both including nothing somebody us\n","        above but inside of someone used\n","        after by into off something via\n","        all can is on such we\n","        although cos it once than what\n","        am do its one that whatever\n","        among down latter onto the when\n","        an each less opposite their where\n","        and either like or them whether\n","        another enough little our these which\n","        any every lots outside they while\n","        anybody everybody many over this who\n","        anyone everyone me own those whoever\n","        anything everything more past though whom\n","        are few most per through whose\n","        around following much plenty till will\n","        as for must plus to with\n","        at from my regarding toward within\n","        be have near same towards without\n","        because he need several under worth\n","        before her neither she unless would\n","        behind him no should unlike yes\n","        below i nobody since until you\n","        beside if none so up your\n","        \"\"\"\n","\n","        functional_words = functional_words.split()\n","        words = RemoveSpecialCHs(text)\n","        count = 0\n","\n","        for i in text:\n","            if i in functional_words:\n","                count += 1\n","\n","        return float(count / len(words))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTJ__98pRM_8","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: CountFunctionalWords(text))\n","posts = posts.withColumn('f', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W1LJfoDRCnwL","colab":{}},"source":["def CountPuncuation(text):\n","    try:\n","        st = [\",\", \".\", \"'\", \"!\", '\"', \";\", \"?\", \":\", \";\"]\n","        count = 0\n","        for i in text:\n","            if (i in st):\n","                count = count + 1\n","        return float(count) / float(len(text))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHcG2YocRNAA","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: CountPuncuation(text))\n","posts = posts.withColumn('p', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"46ZCbcFJGOD5"},"source":["#### functions to find  **Vocabulary Richness Features:**\n","Many quantitative studies rely on the concept of vocabulary richness. A text has low vocabulary richness if the same limited vocabulary is repeated over and over again, while it has high vocabulary richness if new words continually appear. In essence, these features tell us about the diversity and richness of the vocabulary used in the text.\n","\n","* Hapax Legomenon **V**\n","* Hapax DisLegemena(Sichel’s Measure) **V**\n","* Honores R Measure **V**\n","* Brunets Measure W **V** \n","* Yules Characteristic K **V** \n","* Shannon Entropy **V** （also readability feature）\n","* Simpson’s Index **V** （also readability feature）"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4WLniM2vWL2U","colab":{}},"source":["# Hapax Legomenon\n","# TYPE TOKEN RATIO NO OF DIFFERENT WORDS / NO OF WORDS\n","def typeTokenRatio(text):\n","    try:    \n","        words = word_tokenize(text)\n","        return float(len(set(words)) / len(words))\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFIkNmfZRNAF","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: typeTokenRatio(text))\n","posts = posts.withColumn('TTratio', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"quUkV8e1IXb7","colab":{}},"source":["# Hapax DisLegemena (Sichel’s Measure)\n","def hapaxDisLegemena(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        count = 0\n","        # Collections as coll Counter takes an iterable collapse duplicate and counts as\n","        # a dictionary how many equivelant items has been entered\n","        freqs = coll.Counter()\n","        freqs.update(words)\n","        for word in freqs:\n","            if freqs[word] == 2:\n","                count += 1\n","\n","        h = float(count / float(len(words)))\n","        S = float(count / float(len(set(words))))\n","        return [S, h]\n","    except:\n","        return [0,0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffp3HOXqRNAJ","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: hapaxDisLegemena(text)[0])\n","posts = posts.withColumn('SichelesMeasureS', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lq3yK46_RNAL","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: hapaxDisLegemena(text)[1])\n","posts = posts.withColumn('dihapax', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bmDvK_bWGX-P","colab":{}},"source":["# Honore Measure R\n","# return Honore Measure R\n","def hapaxLegemena(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        V1 = 0\n","        # dictionary comprehension . har word kay against value 0 kardi\n","        freqs = {key: 0 for key in words}\n","        for word in words:\n","            freqs[word] += 1\n","        for word in freqs:\n","            if freqs[word] == 1:\n","                V1 += 1\n","        N = len(words)\n","        V = float(len(set(words)))\n","        R = 100 * math.log(N) / max(1, (1 - (V1 / V)))\n","        h = V1 / N\n","        return [R, h]\n","    except:\n","            return [0,0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Y6ScRUFRNAP","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: hapaxLegemena(text)[0])\n","posts = posts.withColumn('HonoreMeasureR', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFh2ql8PRNAQ","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: hapaxLegemena(text)[1])\n","posts = posts.withColumn('hapax', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9ilwbebwWfbI","colab":{}},"source":["# Brunets Measure W\n","# logW = V-a/log(N)\n","# N = total words , V = vocabulary richness (unique words) ,  a=0.17\n","# we can convert into log because we are only comparing different texts\n","def BrunetsMeasureW(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        a = 0.17\n","        V = float(len(set(words)))\n","        N = len(words)\n","        B = (V - a) / (math.log(N))\n","        return float(B)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGHuMiZgRNAU","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: BrunetsMeasureW(text))\n","posts = posts.withColumn('B', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wDsXYhGiJXsg","colab":{}},"source":["# K  10,000 * (M - N) / N**2\n","# , where M  Sigma i**2 * Vi.\n","def YulesCharacteristicK(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        N = len(words)\n","        freqs = coll.Counter()\n","        freqs.update(words)\n","        vi = coll.Counter()\n","        vi.update(freqs.values())\n","        M = sum([(value * value) * vi[value] for key, value in freqs.items()])\n","        K = 10000 * (M - N) / math.pow(N, 2)\n","        return float(K)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oApjWjsTRNAY","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: YulesCharacteristicK(text))\n","posts = posts.withColumn('YuleK', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3Ic20veOGYvw"},"source":["#### functions to find  **Readability Scores:**\n","Readability is the ease with which a reader can understand a written text. Readability is more than simply legibility—which is a measure of how easily a reader can distinguish individual letters or characters from each other. Features for readability stems from the field of linguistics and researchers have frequently used linguistics’ laws (e.g zipfs law) and lemmas to pull out the currently used features to calculate readability scores of text in the modern computer science. Following is the list of features we are using.\n","\n","* Flesch Reading Ease **V**\n","* Flesch-Kincaid Grade Level **V**\n","* Gunning Fog Index  **V**\n","* Dale Chall Readability Formula  **V**\n","* Shannon Entropy (also vocabulary richness feature）**V**\n","* Simpson's Index (also vocabulary richness feature）**V**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"48yRP6S7I-JD","colab":{}},"source":["def FleschReadingEase(text):\n","    try:\n","        NoOfSectences = len(sent_tokenize(text))\n","        words = RemoveSpecialCHs(text)\n","        l = float(len(words))\n","        scount = 0\n","        for word in words:\n","            scount += syllable_count(word)\n","\n","        I = 206.835 - 1.015 * (l / float(NoOfsentences)) - 84.6 * (scount / float(l))\n","        return float(I)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMK03V7PRNAc","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: FleschReadingEase(text))\n","posts = posts.withColumn('FR', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GyYgMIvnI5_m","colab":{}},"source":["def FleschCincadeGradeLevel(text):\n","    try:\n","        NoOfSectences = len(sent_tokenize(text))\n","        words = RemoveSpecialCHs(text)\n","        scount = 0\n","        for word in words:\n","            scount += syllable_count(word)\n","\n","        l = len(words)\n","        F = 0.39 * (l / NoOfSentences) + 11.8 * (scount / float(l)) - 15.59\n","        return float(F)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdvUQxz-RNAg","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: FleschCincadeGradeLevel(text))\n","posts = posts.withColumn('FC', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BBogR5ZfGeNE","colab":{}},"source":["def GunningFoxIndex(text):\n","    try:\n","        NoOfSectences = len(sent_tokenize(text))\n","        words = RemoveSpecialCHs(text)\n","        NoOFWords = float(len(words))\n","        complexWords = 0\n","        for word in words:\n","            if (syllable_count(word) > 2):\n","                complexWords += 1\n","\n","        G = 0.4 * ((NoOFWords / NoOfSentences) + 100 * (complexWords / NoOFWords))\n","        return float(G)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYjt1gLnRNAj","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: GunningFoxIndex(text))\n","posts = posts.withColumn('G', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pu1M89rlItrV","colab":{}},"source":["def dale_chall_readability_formula(text):\n","    try:\n","        NoOfSectences = len(sent_tokenize(text))\n","        words = RemoveSpecialCHs(text)\n","        difficult = 0\n","        adjusted = 0\n","        NoOfWords = len(words)\n","        with open('dale-chall.pkl', 'rb') as f:\n","            fimiliarWords = pickle.load(f)\n","        for word in words:\n","            if word not in fimiliarWords:\n","                difficult += 1\n","        percent = (difficult / NoOfWords) * 100\n","        if (percent > 5):\n","            adjusted = 3.6365\n","        D = 0.1579 * (percent) + 0.0496 * (NoOfWords / NoOfSectences) + adjusted\n","        return float(D)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aaASEJF4RNAo","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: dale_chall_readability_formula(text))\n","posts = posts.withColumn('D', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IH_vl3B3Itum","colab":{}},"source":["# -1*sigma(pi*lnpi)\n","# Shannon and sympsons index are basically diversity indices for any community\n","def ShannonEntropy(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        lenght = len(words)\n","        freqs = coll.Counter()\n","        freqs.update(words)\n","        arr = np.array(list(freqs.values()))\n","        distribution = 1. * arr\n","        distribution /= max(1, lenght)\n","        import scipy as sc\n","        H = sc.stats.entropy(distribution, base=2)\n","        # H = sum([(i/lenght)*math.log(i/lenght,math.e) for i in freqs.values()])\n","        return float(H)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga8hrECVRNAs","colab_type":"code","colab":{}},"source":["find_feature = F.udf(lambda text: ShannonEntropy(text))\n","posts = posts.withColumn('Shannon', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-ieD4nLJItw4","colab":{}},"source":["# 1 - (sigma(n(n - 1))/N(N-1)\n","# N is total number of words\n","# n is the number of each type of word\n","def SimpsonsIndex(text):\n","    try:\n","        words = RemoveSpecialCHs(text)\n","        freqs = coll.Counter()\n","        freqs.update(words)\n","        N = len(words)\n","        n = sum([1.0 * i * (i - 1) for i in freqs.values()])\n","        S = 1 - (n / (N * (N - 1)))\n","        return float(S)\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"snidfpjk5qCn","colab":{}},"source":["find_feature = F.udf(lambda text: SimpsonsIndex(text))\n","posts = posts.withColumn('S', find_feature(F.col('Content')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Tvm2HSWRNAw","colab_type":"code","outputId":"a8f88a60-ea03-4a5a-876a-6e560c0c6fa9","colab":{}},"source":["print((posts.count(), len(posts.columns)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(19464, 36)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDdjvSstRNA0","colab_type":"code","colab":{}},"source":["posts.toPandas().to_csv('posts_match_writing_style.csv',index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUl6PIHTRNA2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x11c329d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark as ps\n",
    "# Import Spark SQL related packages\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.types import FloatType, StringType\n",
    "\n",
    "# Import TextBlob packages for Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "conf = ps.SparkConf().setMaster(\"yarn-client\").setAppName(\"sparK-mer\")\n",
    "conf.set(\"spark.driver.memory\", \"15g\")\n",
    "conf.set(\"spark.executor.heartbeatInterval\",\"3600s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('final')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = spark.read.format(\"csv\").option(\"header\", \"false\").load(\"comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.withColumnRenamed(\"_c0\", \"Comment ID\")\\\n",
    "        .withColumnRenamed(\"_c1\", \"Post ID\")\\\n",
    "        .withColumnRenamed(\"_c2\", \"Content\")\\\n",
    "        .withColumnRenamed(\"_c3\", \"Author\")\\\n",
    "        .withColumnRenamed(\"_c4\", \"Date\")\\\n",
    "        .withColumnRenamed(\"_c5\", \"Vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------+----------+----+\n",
      "|Comment ID|Post ID|             Content|        Author|      Date|Vote|\n",
      "+----------+-------+--------------------+--------------+----------+----+\n",
      "|         1|      1|Seemed to work fine.|       BJ Cook|2010-04-01|   1|\n",
      "|         2|      1|I tried this the ...|  Blitz Surfer|2010-04-01|   1|\n",
      "|         3|      1|A lot of twitter ...|Nischal Shetty|2010-04-01|   1|\n",
      "|         4|      1|Worked a minute a...|   Jonah Grant|2010-04-01|   1|\n",
      "|         5|      1|Yep. At 10:33pm p...| Joshua Guffey|2010-04-01|   1|\n",
      "+----------+-------+--------------------+--------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745866"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixed abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_abbreviation(data_str):\n",
    "    data_str = data_str.lower()\n",
    "    data_str = re.sub(r'\\bthats\\b', 'that is', data_str)\n",
    "    data_str = re.sub(r'\\bive\\b', 'i have', data_str)\n",
    "    data_str = re.sub(r'\\bim\\b', 'i am', data_str)\n",
    "    data_str = re.sub(r'\\bya\\b', 'yeah', data_str)\n",
    "    data_str = re.sub(r'\\bcant\\b', 'can not', data_str)\n",
    "    data_str = re.sub(r'\\bdont\\b', 'do not', data_str)\n",
    "    data_str = re.sub(r'\\bwont\\b', 'will not', data_str)\n",
    "    data_str = re.sub(r'\\bid\\b', 'i would', data_str)\n",
    "    data_str = re.sub(r'wtf', 'what the fuck', data_str)\n",
    "    data_str = re.sub(r'\\bwth\\b', 'what the hell', data_str)\n",
    "    data_str = re.sub(r'\\br\\b', 'are', data_str)\n",
    "    data_str = re.sub(r'\\bu\\b', 'you', data_str)\n",
    "    data_str = re.sub(r'\\bk\\b', 'OK', data_str)\n",
    "    data_str = re.sub(r'\\bsux\\b', 'sucks', data_str)\n",
    "    data_str = re.sub(r'\\bno+\\b', 'no', data_str)\n",
    "    data_str = re.sub(r'\\bcoo+\\b', 'cool', data_str)\n",
    "    data_str = re.sub(r'rt\\b', '', data_str)\n",
    "    data_str = data_str.strip()\n",
    "    return data_str\n",
    "\n",
    "fix_abbreviation_udf = F.udf(fix_abbreviation, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------+----------+----+--------------------+\n",
      "|Comment ID|Post ID|             Content|        Author|      Date|Vote|        fixed_abbrev|\n",
      "+----------+-------+--------------------+--------------+----------+----+--------------------+\n",
      "|         1|      1|Seemed to work fine.|       BJ Cook|2010-04-01|   1|seemed to work fine.|\n",
      "|         2|      1|I tried this the ...|  Blitz Surfer|2010-04-01|   1|i tried this the ...|\n",
      "|         3|      1|A lot of twitter ...|Nischal Shetty|2010-04-01|   1|a lot of twitter ...|\n",
      "|         4|      1|Worked a minute a...|   Jonah Grant|2010-04-01|   1|worked a minute a...|\n",
      "|         5|      1|Yep. At 10:33pm p...| Joshua Guffey|2010-04-01|   1|yep. at 10:33pm p...|\n",
      "+----------+-------+--------------------+--------------+----------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments = comments.withColumn('fixed_abbrev',fix_abbreviation_udf(comments['Content']))\n",
    "comments.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    mention_re = re.compile('@(\\w+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove @mentions\n",
    "    data_str = mention_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 1 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 1:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    # remove unwanted space, *.split() will automatically split on\n",
    "    # whitespace and discard duplicates, the \" \".join() joins the\n",
    "    # resulting list into one string.\n",
    "    return \" \".join(cleaned_str.split())\n",
    "\n",
    "remove_features_udf = F.udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------+----------+----+--------------------+--------------------+\n",
      "|Comment ID|Post ID|             Content|        Author|      Date|Vote|        fixed_abbrev|             removed|\n",
      "+----------+-------+--------------------+--------------+----------+----+--------------------+--------------------+\n",
      "|         1|      1|Seemed to work fine.|       BJ Cook|2010-04-01|   1|seemed to work fine.| seemed to work fine|\n",
      "|         2|      1|I tried this the ...|  Blitz Surfer|2010-04-01|   1|i tried this the ...|tried this the fi...|\n",
      "|         3|      1|A lot of twitter ...|Nischal Shetty|2010-04-01|   1|a lot of twitter ...|lot of twitter ap...|\n",
      "|         4|      1|Worked a minute a...|   Jonah Grant|2010-04-01|   1|worked a minute a...|worked minute ago...|\n",
      "|         5|      1|Yep. At 10:33pm p...| Joshua Guffey|2010-04-01|   1|yep. at 10:33pm p...|yep at pm pst it ...|\n",
      "+----------+-------+--------------------+--------------+----------+----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments = comments.withColumn('removed',remove_features_udf(comments['Content']))\n",
    "comments.show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "sentiment_analysis_udf = F.udf(sentiment_analysis , FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------+----------+----+---------------+\n",
      "|Comment ID|Post ID|             Content|        Author|      Date|Vote|sentiment_score|\n",
      "+----------+-------+--------------------+--------------+----------+----+---------------+\n",
      "|         1|      1|Seemed to work fine.|       BJ Cook|2010-04-01|   1|     0.41666666|\n",
      "|         2|      1|I tried this the ...|  Blitz Surfer|2010-04-01|   1|          0.125|\n",
      "|         3|      1|A lot of twitter ...|Nischal Shetty|2010-04-01|   1|            0.5|\n",
      "|         4|      1|Worked a minute a...|   Jonah Grant|2010-04-01|   1|            0.0|\n",
      "|         5|      1|Yep. At 10:33pm p...| Joshua Guffey|2010-04-01|   1|     0.20888889|\n",
      "+----------+-------+--------------------+--------------+----------+----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments  = comments.withColumn(\"sentiment_score\", sentiment_analysis_udf( comments['fixed_abbrev'] ))\n",
    "comments = comments.drop('fixed_abbrev').drop('removed')\n",
    "comments.show(5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Average Sentiment Score for each Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sentiment= comments.groupBy(['Post ID']).agg(F.avg('sentiment_score').alias('avg_senti_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|Post ID|    avg_senti_score|\n",
      "+-------+-------------------+\n",
      "|    675| 0.0335309744157173|\n",
      "|   5925|0.11772260677231394|\n",
      "|    691|0.11745779495686293|\n",
      "|   6194| 0.1919174811582228|\n",
      "|   6240|0.13226061725081542|\n",
      "+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_sentiment.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sentiment.toPandas().to_csv('post_sentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
